\section{Thiết kế thực nghiệm}
Thực nghiệm sử dụng framework của Carlini và Wagner. Với cả tấn công EAD và C\&W, tác giả đều sử dụng các tham số cấu hình mặc định, trong đó triển khai 9 bước tìm kiếm nhị phân trên tham số hiệu chỉnh  (bắt đầu từ 0.001) và chạy  vòng lặp cho mỗi bước với learning rate khởi tạo . Để tìm các mẫu đối nghịch thành công, tác giả sử dụng thuật toán tối ưu tham chiếu (ADAM) cho C\&W, và sử dụng thuật toán chiếu FISTA (thuật toán 1) với square-root decaying learning rate cho EAD. Tương tự tấn công C\&W, mẫu đối nghịch cuối cùng tìm được từ EAD được chọn là mẫu nhiễu ít nhất giữa các mẫu đối nghịch thành công. Độ nhạy cảm của L1 (tham số  ) và tác động của luật chọn trong EAD sẽ được bàn đến ở phần sau. Tác giả đặt tham số tấn công chuyển giao $\kappa = 0$ cho cả EAD và C\&W.
\begin{center}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{cc|c|c|c}
        \hline
        && Best case & Average case & Worst case \\
        \hline
        Optimization method & $\beta$  
        & \begin{tabular}{cccc}
            ASR & $L_1$ & $L_2$ & $L_{\infty}$
        \end{tabular}
        & \begin{tabular}{cccc}
            ASR & $L_1$ & $L_2$ & $L_{\infty}$
        \end{tabular}
        & \begin{tabular}{cccc}
            ASR & $L_1$ & $L_2$ & $L_{\infty}$
        \end{tabular} \\  
        \hline    
    \end{tabular}}
\end{center}

Tác giả triển khai FGM và I-FGM bằng gói thư viện CleverHans. Tham số nhiễu tốt nhất $\epsilon$ được xác định bằng phương pháp tìm kiếm lưới fine-grained trên mỗi ảnh, $\epsilon$ nhỏ nhất trong lưới thể hiện tấn công thành công sẽ được ghi lại. Với I-FGM, tác giả thực hiện $10$ vòng lặp FGM ($10$ là giá trị mặc định) với $\epsilon$-ball clipping. Tham số nhiễu $\epsilon'$ trong mỗi vòng lặp FGM được đặt là $\epsilon/10$ , đã được chứng minh hiệu quả trong (Tram`er et al. 2017). Dải giá trị của lưới và độ phân giải của 2 phương pháp trên được đề cập cụ thể trong tài liệu bổ sung 1.

Việc phân loại ảnh cho tập MNIST và CIFAIR10 được huấn luyện trên mô hình DNN bởi Carlini and Wagner. Để phân loại cho tập ImageNet, người ta dùng mô hình Inception-v3 (Szegedy et al. 2016). Đối với tập MNIST và CIFAIR10, tác giả lấy ngẫu nhiên trong tập test 1000 ảnh đã được phân loại đúng để tấn công làm phân loại sai. Với tập ImageNet, tác giả chọn ngẫu nhiên 100 ảnh đã được phân loại đúng và 9 ảnh được phân loại sai để tấn công. Tất cả thực nghiệm được triển khai trên thiết bị phần cứng Intel E5-2690 v3 CPU, 40 GB RAM, single NVIDIA K80 GPU.