\subsection{Hướng nghiên cứu mở rộng}
\subsubsection{Thuật toán tổng quát}
Trong báo cáo này, tác giả đã sử dụng thuật toán FISTA (phiên bản nhanh hơn của ISTA) để cực tiểu hóa hàm $f(\mathbf{x}, t)$ trong phương trình \ref{eq:7}. Để tính được gradient $\nabla g$ ta cần có ràng buộc hàm mất mát của mô hình gốc $f$ phải trơn. Tuy nhiên trong thực tế, không phải tất cả các hàm mất mát đều trơn! Trong bài báo này, tác giả lấy gradient được tính bởi mạng DNN. Thực chất trong code triển khai (sử dụng TensorFlow), gradient được tính bởi mạng là sub-gradient (khi sử dụng hàm kích hoạt là ReLU, vốn dĩ không phải một hàm trơn). Chính vì vậy ta cần một thuật toán tổng quát hơn để giải bài toán (\ref{eq:7}) với một hàm $f$ (lồi) bất kì mà không cần ràng buộc về tính trơn của nó. (Shao, Weijia, Fikret Sivrikaya, \& Sahin Albayrak 2022) đã giới thiệu một thuật toán hiệu quả để cực tiểu hóa hàm mục tiêu tổ hợp bằng cập nhật mũ. Bài báo đưa ra thuật toán cho hiệu chỉnh elastic-net và thực nghiệm trên tập CIFAR. Thuật toán này được so sánh với FISTA và hội tụ nhanh hơn sau 200 vòng lặp. Chúng tôi mong muốn cài đặt thuật toán này để tạo mẫu đối nghịch sau đó so sánh tỉ lệ thành công, các độ đo $L_1$, $L_2$ và $L_{\infty}$ cùng với thời gian chạy thực tế so với EAD.
\subsubsection{Tấn công nhận diện khuôn mặt}
Chúng tôi mong muốn sử dụng EAD để tấn công hệ thống nhận diện bằng khuôn mặt. Mục tiêu là một tấn công leo thang đặc quyền khi sử dụng khuôn mặt của một nhân viên với quyền thấp hơn để đánh lừa mô hình nhận diện thành một nhân viên với quyền cao hơn. Tấn công này thúc đẩy việc hệ thống nhận diện phải được phòng thủ một cách cẩn thận. Gần đây framework foolbox \footnote{https://github.com/bethgelab/foolbox} cũng đã tích hợp sẵn tấn công EAD cũng như C\&W để sinh ra các mẫu đối nghịch. Foolbox đã cài đặt EAD để phù hợp với cả Tensorflow lần PyTorch.


